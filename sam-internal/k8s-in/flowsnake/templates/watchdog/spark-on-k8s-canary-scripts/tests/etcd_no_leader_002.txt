{"class": "SPARK_SUBMIT_FAILED", "exception": "KubernetesClientException", "exception_cause": "ETCD_NO_LEADER"}
0522 02:37:41 [1558492661] spark-pi-709d5791 - ======== Beginning spark-pi-709d5791 test ========
0522 02:37:41 [1558492661] spark-pi-709d5791 -  [0;32mKubernetes master [0m is running at  [0;33mhttps://10.254.208.1:443 [0m
0522 02:37:41 [1558492661] spark-pi-709d5791 -
0522 02:37:41 [1558492661] spark-pi-709d5791 - To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
0522 02:37:43 [1558492663] spark-pi-709d5791 - Cleaning up SparkApplication/Pod older than 1 hours from prior runs.
0522 02:37:44 [1558492664] spark-pi-709d5791 - Creating SparkApplication spark-pi-709d5791
0522 02:37:44 [1558492664] spark-pi-709d5791 - sparkapplication "spark-pi-709d5791" created
0522 02:37:45 [1558492665] spark-pi-709d5791 - Waiting for SparkApplication spark-pi-709d5791 to reach a terminal state.
0522 02:37:50 [1558492670] spark-pi-709d5791 - Pod change detected: spark-pi-709d5791-driver: Pending on host <none>.
0522 02:38:01 [1558492681] spark-pi-709d5791 - Pod change detected: spark-pi-709d5791-driver changed to Terminating (previously Pending).
0522 02:38:02 [1558492682] spark-pi-709d5791 - SparkApplication spark-pi-709d5791 has terminated after 17 seconds. State is FAILED.
0522 02:38:03 [1558492683] spark-pi-709d5791 - ---- Begin Events ----
0522 02:38:03 [1558492683] spark-pi-709d5791 - Name:         spark-pi-709d5791
0522 02:38:03 [1558492683] spark-pi-709d5791 - Events:
0522 02:38:03 [1558492683] spark-pi-709d5791 -   Type     Reason                            Age   From            Message
0522 02:38:03 [1558492683] spark-pi-709d5791 -   ----     ------                            ----  ----            -------
0522 02:38:03 [1558492683] spark-pi-709d5791 -   Normal   SparkApplicationAdded             20s   spark-operator  SparkApplication spark-pi-709d5791 was added, enqueuing it for submission
0522 02:38:03 [1558492683] spark-pi-709d5791 -   Warning  SparkApplicationSubmissionFailed  6s    spark-operator  failed to submit SparkApplication spark-pi-709d5791: failed to run spark-submit for SparkApplication flowsnake-watchdog/spark-pi-709d5791: SLF4J: Class path contains multiple SLF4J bindings.
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Found binding in [jar:file:/opt/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Found binding in [jar:file:/usr/local/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
0522 02:38:03 [1558492683] spark-pi-709d5791 - Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.254.208.1/api/v1/namespaces/flowsnake-watchdog/configmaps. Message: client: etcd member https://shared0-flowsnakemasterprod1-1-yul.ops.sfdc.net:2379 has no leader. Received status: Status(apiVersion=v1, code=500, details=null, kind=Status, message=client: etcd member https://shared0-flowsnakemasterprod1-1-yul.ops.sfdc.net:2379 has no leader, metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=null, status=Failure, additionalProperties={}).
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:226)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:769)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:360)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.handlers.ConfigMapHandler.create(ConfigMapHandler.java:43)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.handlers.ConfigMapHandler.create(ConfigMapHandler.java:32)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:208)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:66)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:146)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:140)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:140)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:250)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:241)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:241)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:204)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
0522 02:38:03 [1558492683] spark-pi-709d5791 -            at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   Warning  SparkApplicationFailed  5s  spark-operator  SparkApplication spark-pi-709d5791 failed: failed to run spark-submit for SparkApplication flowsnake-watchdog/spark-pi-709d5791: SLF4J: Class path contains multiple SLF4J bindings.
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Found binding in [jar:file:/opt/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Found binding in [jar:file:/usr/local/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
0522 02:38:03 [1558492683] spark-pi-709d5791 - SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
0522 02:38:03 [1558492683] spark-pi-709d5791 - Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.254.208.1/api/v1/namespaces/flowsnake-watchdog/configmaps. Message: client: etcd member https://shared0-flowsnakemasterprod1-1-yul.ops.sfdc.net:2379 has no leader. Received status: Status(apiVersion=v1, code=500, details=null, kind=Status, message=client: etcd member https://shared0-flowsnakemasterprod1-1-yul.ops.sfdc.net:2379 has no leader, metadata=ListMeta(resourceVersion=null, selfLink=null, additionalProperties={}), reason=null, status=Failure, additionalProperties={}).
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:409)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:226)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:769)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:360)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.handlers.ConfigMapHandler.create(ConfigMapHandler.java:43)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.handlers.ConfigMapHandler.create(ConfigMapHandler.java:32)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:208)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at io.fabric8.kubernetes.client.dsl.internal.NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.createOrReplace(NamespaceVisitFromServerGetWatchDeleteRecreateWaitApplicableListImpl.java:66)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:146)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:140)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:140)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:250)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:241)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:241)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:204)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
0522 02:38:03 [1558492683] spark-pi-709d5791 -   at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
0522 02:38:07 [1558492687] spark-pi-709d5791 - ---- End Events ----
0522 02:38:08 [1558492688] spark-pi-709d5791 - Cannot locate driver pod. Maybe it never started? No logs to display.
0522 02:38:08 [1558492688] spark-pi-709d5791 - -------- Executor Pods ----------
0522 02:38:08 [1558492688] spark-pi-709d5791 - Cleaning up stuff for complated or failed test.
0522 02:38:08 [1558492688] spark-pi-709d5791 - sparkapplication "spark-pi-709d5791" deleted
0522 02:38:10 [1558492690] spark-pi-709d5791 - ======== Completion of spark-pi-709d5791 test, returning 1 ========
