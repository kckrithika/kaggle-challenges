{"class": "SPARK_CONTEXT_INIT_ERROR", "exception": "KubernetesClientException", "exception_cause": "RBAC"}
0520 08:28:00 [1558340880] spark-impersonation-f91e6121 - ======== Beginning spark-impersonation-f91e6121 test ========
0520 08:28:00 [1558340880] spark-impersonation-f91e6121 -  [0;32mKubernetes master [0m is running at  [0;33mhttps://kubernetes-api-flowsnake-ph2.slb.sfdc.net [0m
0520 08:28:00 [1558340880] spark-impersonation-f91e6121 -
0520 08:28:00 [1558340880] spark-impersonation-f91e6121 - To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
0520 08:28:01 [1558340881] spark-impersonation-f91e6121 - Cleaning up SparkApplication/Pod older than 1 hours from prior runs.
0520 08:28:02 [1558340882] spark-impersonation-f91e6121 - Creating SparkApplication spark-impersonation-f91e6121
0520 08:28:02 [1558340882] spark-impersonation-f91e6121 - sparkapplication "spark-impersonation-f91e6121" created
0520 08:28:03 [1558340883] spark-impersonation-f91e6121 - Waiting for SparkApplication spark-impersonation-f91e6121 to reach a terminal state.
0520 08:28:10 [1558340890] spark-impersonation-f91e6121 - Pod change detected: spark-impersonation-f91e6121-driver: Init:0/1 on host shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net.
0520 08:28:13 [1558340893] spark-impersonation-f91e6121 - Pod change detected: spark-impersonation-f91e6121-driver changed to PodInitializing (previously Init:0/1).
0520 08:28:15 [1558340895] spark-impersonation-f91e6121 - Pod change detected: spark-impersonation-f91e6121-driver changed to Running (previously PodInitializing).
0520 08:29:04 [1558340944] spark-impersonation-f91e6121 - ...still waiting for terminal state (currently RUNNING) after 61 seconds.
0520 08:29:04 [1558340944] spark-impersonation-f91e6121 - ---- Begin Events ----
0520 08:29:04 [1558340944] spark-impersonation-f91e6121 - Name:         spark-impersonation-f91e6121
0520 08:29:04 [1558340944] spark-impersonation-f91e6121 - Events:                          <none>
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 - Name:           spark-impersonation-f91e6121-driver
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 - Events:
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Type     Reason                 Age   From                                                       Message
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   ----     ------                 ----  ----                                                       -------
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "tokens"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "client-key"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "client-certificate"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "certificate-authority"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-local-dir-1"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Warning  FailedMount            58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp failed for volume "spark-conf-volume" : configmaps "spark-impersonation-f91e6121-1558340888348-driver-conf-map" not found
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-driver-flowsnake-watchdog-token-29g44"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  58s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "datacerts"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Scheduled              58s   default-scheduler                                          Successfully assigned spark-impersonation-f91e6121-driver to shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  57s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-conf-volume"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Pulled                 57s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Container image "ops0-artifactrepo1-0-ph2.data.sfdc.net/tnrp/sam/madkub:1.0.0-0000084-9f4a6ca6" already present on machine
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Created                57s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Created container
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Started                56s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Started container
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Pulling                55s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  pulling image "ops0-artifactrepo1-0-ph2.data.sfdc.net/dva/flowsnake-spark-on-k8s-sample-apps:4"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Pulled                 54s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Successfully pulled image "ops0-artifactrepo1-0-ph2.data.sfdc.net/dva/flowsnake-spark-on-k8s-sample-apps:4"
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Created                54s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Created container
0520 08:29:06 [1558340946] spark-impersonation-f91e6121 -   Normal   Started                54s   kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Started container
0520 08:29:08 [1558340948] spark-impersonation-f91e6121 - ---- End Events ----
0520 08:29:14 [1558340954] spark-impersonation-f91e6121 - Pod change detected: spark-impersonation-f91e6121-driver changed to Error (previously Running).
0520 08:29:15 [1558340955] spark-impersonation-f91e6121 - SparkApplication spark-impersonation-f91e6121 has terminated after 72 seconds. State is FAILED.
0520 08:29:16 [1558340956] spark-impersonation-f91e6121 - ---- Begin Events ----
0520 08:29:16 [1558340956] spark-impersonation-f91e6121 - Name:         spark-impersonation-f91e6121
0520 08:29:16 [1558340956] spark-impersonation-f91e6121 - Events:                          <none>
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 - Name:           spark-impersonation-f91e6121-driver
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 - Events:
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Type     Reason                 Age   From                                                       Message
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   ----     ------                 ----  ----                                                       -------
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "tokens"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "client-key"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "client-certificate"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "certificate-authority"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-local-dir-1"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Warning  FailedMount            1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp failed for volume "spark-conf-volume" : configmaps "spark-impersonation-f91e6121-1558340888348-driver-conf-map" not found
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-driver-flowsnake-watchdog-token-29g44"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "datacerts"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Scheduled              1m    default-scheduler                                          Successfully assigned spark-impersonation-f91e6121-driver to shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   SuccessfulMountVolume  1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  MountVolume.SetUp succeeded for volume "spark-conf-volume"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Pulled                 1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Container image "ops0-artifactrepo1-0-ph2.data.sfdc.net/tnrp/sam/madkub:1.0.0-0000084-9f4a6ca6" already present on machine
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Created                1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Created container
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Started                1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Started container
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Pulling                1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  pulling image "ops0-artifactrepo1-0-ph2.data.sfdc.net/dva/flowsnake-spark-on-k8s-sample-apps:4"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Pulled                 1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Successfully pulled image "ops0-artifactrepo1-0-ph2.data.sfdc.net/dva/flowsnake-spark-on-k8s-sample-apps:4"
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Created                1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Created container
0520 08:29:18 [1558340958] spark-impersonation-f91e6121 -   Normal   Started                1m    kubelet, shared0-flowsnakeworkerprod1-22-ph2.ops.sfdc.net  Started container
0520 08:29:20 [1558340960] spark-impersonation-f91e6121 - ---- End Events ----
0520 08:29:20 [1558340960] spark-impersonation-f91e6121 - ---- Begin pods/spark-impersonation-f91e6121-driver Log ----
++ id -u
+ myuid=0
++ id -g
+ mygid=0
+ set +e
++ getent passwd 0
+ uidentry=root:x:0:0:root:/root:/bin/bash
+ set -e
+ '[' -z root:x:0:0:root:/root:/bin/bash ']'
+ SPARK_K8S_CMD=driver
+ case "$SPARK_K8S_CMD" in
+ shift 1
+ SPARK_CLASSPATH=':/opt/spark/jars/*'
+ env
+ grep SPARK_JAVA_OPT_
+ sort -t_ -k4 -n
+ sed 's/[^=]*=\(.*\)/\1/g'
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ '[' -n '' ']'
+ '[' -n '' ']'
+ PYSPARK_ARGS=
+ '[' -n '' ']'
+ R_ARGS=
+ '[' -n '' ']'
+ '[' '' == 2 ']'
+ '[' '' == 3 ']'
+ case "$SPARK_K8S_CMD" in
+ CMD=("$SPARK_HOME/bin/spark-submit" --conf "spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS" --deploy-mode client "$@")
+ exec /sbin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=10.178.99.103 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class org.apache.spark.examples.SparkPi spark-internal
2019-05-20 08:28:25 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-20 08:28:31 INFO  SparkContext:54 - Running Spark version 2.4.0-sfdc-0.2-SNAPSHOT
2019-05-20 08:28:31 INFO  SparkContext:54 - Submitted application: Spark Pi
2019-05-20 08:28:32 INFO  SecurityManager:54 - Changing view acls to: root
2019-05-20 08:28:32 INFO  SecurityManager:54 - Changing modify acls to: root
2019-05-20 08:28:32 INFO  SecurityManager:54 - Changing view acls groups to:
2019-05-20 08:28:32 INFO  SecurityManager:54 - Changing modify acls groups to:
2019-05-20 08:28:32 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2019-05-20 08:28:37 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 7078.
2019-05-20 08:28:38 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-05-20 08:28:38 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-05-20 08:28:38 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-05-20 08:28:38 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-05-20 08:28:38 INFO  DiskBlockManager:54 - Created local directory at /var/data/spark-239b5154-7dde-4edb-b6b6-38562d49cefa/blockmgr-a018f02f-6d3c-489c-84e3-5dfcc5beb084
2019-05-20 08:28:38 INFO  MemoryStore:54 - MemoryStore started with capacity 93.3 MB
2019-05-20 08:28:38 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-05-20 08:28:39 INFO  log:192 - Logging initialized @23597ms
2019-05-20 08:28:39 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-05-20 08:28:39 INFO  Server:419 - Started @24394ms
2019-05-20 08:28:40 INFO  AbstractConnector:278 - Started ServerConnector@20d11153{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-05-20 08:28:40 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62a8fd44{/jobs,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@155d1021{/jobs/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4bd2f0dc{/jobs/job,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2c42b421{/jobs/job/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51e37590{/stages,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@deb3b60{/stages/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@701a32{/stages/stage,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27cbfddf{/stages/stage/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27ead29e{/stages/pool,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4c060c8f{/stages/pool/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40620d8e{/storage,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@383f3558{/storage/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49b07ee3{/storage/rdd,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@352e612e{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f00478{/environment,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2424686b{/environment/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ea94d6a{/executors,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28486680{/executors/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d7e7435{/executors/threadDump,null,AVAILABLE,@Spark}
2019-05-20 08:28:40 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a1e3ac1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e78fcf5{/static,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69e308c6{/,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a1ed4e5{/api,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1efdcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1623bbe5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-05-20 08:28:41 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://spark-impersonation-f91e6121-1558340888348-driver-svc.flowsnake-watchdog.svc:4040
2019-05-20 08:28:41 INFO  SparkContext:54 - Added JAR file:///sample-apps/sample-basic-spark-operator/sample-basic-spark-operator.jar at spark://spark-impersonation-f91e6121-1558340888348-driver-svc.flowsnake-watchdog.svc:7078/jars/sample-basic-spark-operator.jar with timestamp 1558340921891
2019-05-20 08:29:04 INFO  ExecutorPodsAllocator:54 - Going to request 1 executors from Kubernetes.
2019-05-20 08:29:05 WARN  WatchConnectionManager:185 - Exec Failure: HTTP 403, Status: 403 - pods is forbidden: User "system:serviceaccount:flowsnake-watchdog:spark-driver-flowsnake-watchdog" cannot watch pods in the namespace "flowsnake-watchdog": [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found]
java.net.ProtocolException: Expected HTTP 101 response but was '403 Forbidden'
	at okhttp3.internal.ws.RealWebSocket.checkResponse(RealWebSocket.java:216)
	at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:183)
	at okhttp3.RealCall$AsyncCall.execute(RealCall.java:141)
	at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-05-20 08:29:05 ERROR SparkContext:91 - Error initializing SparkContext.
io.fabric8.kubernetes.client.KubernetesClientException: pods is forbidden: User "system:serviceaccount:flowsnake-watchdog:spark-driver-flowsnake-watchdog" cannot watch pods in the namespace "flowsnake-watchdog": [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found]
	at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager$2.onFailure(WatchConnectionManager.java:188)
	at okhttp3.internal.ws.RealWebSocket.failWebSocket(RealWebSocket.java:543)
	at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:185)
	at okhttp3.RealCall$AsyncCall.execute(RealCall.java:141)
	at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-05-20 08:29:06 INFO  AbstractConnector:318 - Stopped Spark@20d11153{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-05-20 08:29:06 INFO  SparkUI:54 - Stopped Spark web UI at http://spark-impersonation-f91e6121-1558340888348-driver-svc.flowsnake-watchdog.svc:4040
2019-05-20 08:29:06 INFO  KubernetesClusterSchedulerBackend:54 - Shutting down all executors
2019-05-20 08:29:07 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Asking each executor to shut down
2019-05-20 08:29:10 ERROR Utils:91 - Uncaught exception in thread kubernetes-executor-snapshots-subscribers-1
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://kubernetes.default.svc/api/v1/namespaces/flowsnake-watchdog/pods. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods is forbidden: User "system:serviceaccount:flowsnake-watchdog:spark-driver-flowsnake-watchdog" cannot create pods in the namespace "flowsnake-watchdog": [clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found].
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:407)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:226)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:769)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:356)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator$$anonfun$org$apache$spark$scheduler$cluster$k8s$ExecutorPodsAllocator$$onNewSnapshots$1.apply$mcVI$sp(ExecutorPodsAllocator.scala:137)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsAllocator$$onNewSnapshots(ExecutorPodsAllocator.scala:124)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator$$anonfun$start$1.apply(ExecutorPodsAllocator.scala:68)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator$$anonfun$start$1.apply(ExecutorPodsAllocator.scala:68)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$$anonfun$org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$$callSubscriber$1.apply$mcV$sp(ExecutorPodsSnapshotsStoreImpl.scala:102)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$$callSubscriber(ExecutorPodsSnapshotsStoreImpl.scala:99)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$$anonfun$addSubscriber$1.apply$mcV$sp(ExecutorPodsSnapshotsStoreImpl.scala:71)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$$anon$1.run(ExecutorPodsSnapshotsStoreImpl.scala:107)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-05-20 08:29:10 ERROR Utils:91 - Uncaught exception in thread main
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://kubernetes.default.svc/api/v1/namespaces/flowsnake-watchdog/pods?labelSelector=spark-app-selector%3Dspark-application-1558340943494,spark-role%3Dexecutor. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. pods is forbidden: User "system:serviceaccount:flowsnake-watchdog:spark-driver-flowsnake-watchdog" cannot list pods in the namespace "flowsnake-watchdog": [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found].
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:470)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:407)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:379)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:343)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:327)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.list(BaseOperation.java:605)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.deleteList(BaseOperation.java:692)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:636)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.delete(BaseOperation.java:70)
	at org.apache.spark.scheduler.cluster.k8s.KubernetesClusterSchedulerBackend$$anonfun$stop$4.apply$mcV$sp(KubernetesClusterSchedulerBackend.scala:89)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.scheduler.cluster.k8s.KubernetesClusterSchedulerBackend.stop(KubernetesClusterSchedulerBackend.scala:85)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:581)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2040)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:585)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:926)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
	at org.apache.spark.examples.SparkPi$.main(SparkPi.scala:31)
	at org.apache.spark.examples.SparkPi.main(SparkPi.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2019-05-20 08:29:10 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-05-20 08:29:10 INFO  MemoryStore:54 - MemoryStore cleared
2019-05-20 08:29:10 INFO  BlockManager:54 - BlockManager stopped
2019-05-20 08:29:10 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-05-20 08:29:10 WARN  MetricsSystem:66 - Stopping a MetricsSystem that is not running
2019-05-20 08:29:10 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-05-20 08:29:11 INFO  SparkContext:54 - Successfully stopped SparkContext
Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: pods is forbidden: User "system:serviceaccount:flowsnake-watchdog:spark-driver-flowsnake-watchdog" cannot watch pods in the namespace "flowsnake-watchdog": [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found]
	at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager$2.onFailure(WatchConnectionManager.java:188)
	at okhttp3.internal.ws.RealWebSocket.failWebSocket(RealWebSocket.java:543)
	at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:185)
	at okhttp3.RealCall$AsyncCall.execute(RealCall.java:141)
	at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-05-20 08:29:11 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-05-20 08:29:11 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-ea5382f7-ba2a-4c45-9fba-296528024596
2019-05-20 08:29:11 INFO  ShutdownHookManager:54 - Deleting directory /var/data/spark-239b5154-7dde-4edb-b6b6-38562d49cefa/spark-7802bca8-0f90-4e13-80b1-a46ed92dbfd6
0520 08:29:21 [1558340961] spark-impersonation-f91e6121 - ---- End pods/spark-impersonation-f91e6121-driver Log ----
0520 08:29:21 [1558340961] spark-impersonation-f91e6121 - -------- Executor Pods ----------
0520 08:29:21 [1558340961] spark-impersonation-f91e6121 - Cleaning up stuff for complated or failed test.
0520 08:29:21 [1558340961] spark-impersonation-f91e6121 - sparkapplication "spark-impersonation-f91e6121" deleted
0520 08:29:22 [1558340962] spark-impersonation-f91e6121 - ======== Completion of spark-impersonation-f91e6121 test, returning 1 ========
