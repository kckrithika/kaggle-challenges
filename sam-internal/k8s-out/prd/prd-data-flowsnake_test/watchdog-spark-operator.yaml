apiVersion: v1
items:
- apiVersion: v1
  automountServiceAccountToken: true
  kind: ServiceAccount
  metadata:
    name: watchdog-spark-operator-serviceaccount
    namespace: flowsnake
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    annotations:
      manifestctl.sam.data.sfdc.net/swagger: disable
    name: watchdog-spark-operator-rolebinding
    namespace: flowsnake-watchdog
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: flowsnake-client-flowsnake-watchdog-Role
  subjects:
  - kind: ServiceAccount
    name: watchdog-spark-operator-serviceaccount
    namespace: flowsnake
- apiVersion: v1
  data:
    watchdog-spark-operator.json: '{"apiVersion": "sparkoperator.k8s.io/v1beta1",
      "kind": "SparkApplication", "metadata": {"name": "watchdog-spark-operator",
      "namespace": "flowsnake-watchdog"}, "spec": {"deps": {"jars": ["local:///sample-apps/sample-spark-operator/extra-jars/*"]},
      "driver": {"coreLimit": "200m", "cores": 0.10000000000000001, "labels": {"version":
      "2.4.0"}, "memory": "512m", "serviceAccount": "spark-driver-flowsnake-watchdog"},
      "executor": {"cores": 1, "instances": 1, "labels": {"version": "2.4.0"}, "memory":
      "512m"}, "image": "ops0-artifactrepo2-0-prd.data.sfdc.net/dva/flowsnake-spark-on-k8s-sample-apps:jenkins-dva-transformation-spark-on-k8s-sample-apps-PR-2-1-itest",
      "imagePullPolicy": "Always", "mainApplicationFile": "local:///sample-apps/sample-spark-operator/sample-spark-operator.jar",
      "mainClass": "org.apache.spark.examples.SparkPi", "mode": "cluster", "restartPolicy":
      {"type": "Never"}, "sparkVersion": "", "type": "Scala"}}'
  kind: ConfigMap
  metadata:
    name: watchdog-spark-on-k8s-spec-configmap
    namespace: flowsnake
- apiVersion: v1
  data:
    check-spark-operator-v2.sh: |
      #!/usr/bin/bash
      set -o nounset
      set -o errexit
      set -o pipefail

      # Parse command line arguments. https://stackoverflow.com/a/14203146
      POSITIONAL=()
      while [[ $# -gt 0 ]]
      do
      key="$1"

      case $key in
          --impersonation-proxy)
          IMPERSONATION_PROXY="true"
          shift
          ;;
          *)    # unknown option
          POSITIONAL+=("$1") # save it in an array for later
          shift # past argument
          ;;
      esac
      done
      set -- "${POSITIONAL[@]}" # restore positional parameters

      if [[ -z "$IMPERSONATION_PROXY" ]]; then
          # Disable use of SAM's custom kubeconfig, restore default Kubernetes behavior (this cluster's kubeapi using service account token)
          unset KUBECONFIG
      else
          # Use a custom kubeconfig to access via MadDog PKI certs and Impersonation Proxy
          export KUBECONFIG=/watchdog-spark-operator/kubeconfig-impersonation-proxy
      fi

      kc() {
        kubectl "$@"
      }
      kcfw() {
        kc -n flowsnake-watchdog "$@"
      }

      SPEC=$1
      APP_NAME=$(python -c 'import json,sys; print json.load(sys.stdin)["metadata"]["name"]' < $SPEC)
      APP_NAMESPACE=$(python -c 'import json,sys; print json.load(sys.stdin)["metadata"]["namespace"]' < $SPEC)
      SELECTOR="sparkoperator.k8s.io/app-name=$APP_NAME"

      echo "Cleaning up $APP_NAME resources from prior runs"
      # || true because exit code 1 if spark application can't be found.
      kcfw delete sparkapplication $APP_NAME || true
      # kubectl returns success even if no pods match the label selector. This is helpful,
      # this will have the side-effect of aborting the script early if it cannot access kubeapi.
      kcfw delete pod -l $SELECTOR
      # Wait for pods from prior runs to delete.
      while ! $(kcfw get pod -l $SELECTOR 2>&1 | grep "No resources" > /dev/null); do sleep 1; done;

      echo "Creating SparkApplication $APP_NAME"
      kcfw create -f /watchdog-spark-specs/$SPEC

      echo "Waiting for SparkApplication $APP_NAME to complete"
      # Terminal values are COMPLETED and FAILED https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md#the-crd-controller
      while ! $(kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}' | grep -P '(COMPLETED|FAILED)' > /dev/null); do sleep 1; done;
      echo ---- Begin Spark Driver Log ----
      kcfw logs $(kc -n $APP_NAMESPACE get pod -l $SELECTOR -o name) || true
      echo ---- End Spark Driver Log ----
      echo "Terminal SparkApplication $APP_NAME state is $(kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}')"
      # Test successful iff final state is COMPLETED. Use exit code from grep.
      kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}' | grep COMPLETED > /dev/null
    check-spark-operator.sh: |
      #!/usr/bin/bash
      set -o nounset
      set -o errexit
      set -o pipefail

      # Disable use of SAM's custom kubeconfig
      unset KUBECONFIG

      kcfw() {
        kubectl -n flowsnake-watchdog "$@"
      }

      SPEC=$1
      APP_NAME=$(basename ${SPEC%.*}) # /watchdog-spark-specs/watchdog-spark-operator.json -> watchdog-spark-operator
      SELECTOR="sparkoperator.k8s.io/app-name=$APP_NAME"

      echo "Cleaning up $APP_NAME resources from prior runs"
      # || true because exit code 1 if spark application can't be found.
      kcfw delete sparkapplication $APP_NAME || true
      # kubectl returns success even if no pods match the label selector. This is helpful,
      # this will have the side-effect of aborting the script early if it cannot access kubeapi.
      kcfw delete pod -l $SELECTOR
      # Wait for pods from prior runs to delete.
      while ! $(kcfw get pod -l $SELECTOR 2>&1 | grep "No resources" > /dev/null); do sleep 1; done;

      echo "Creating SparkApplication $APP_NAME"
      kcfw create -f $SPEC

      echo "Waiting for SparkApplication $APP_NAME to complete"
      # Terminal values are COMPLETED and FAILED https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md#the-crd-controller
      while ! $(kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}' | grep -P '(COMPLETED|FAILED)' > /dev/null); do sleep 1; done;
      echo ---- Begin Spark Driver Log ----
      kcfw logs $(kcfw get pod -l $SELECTOR -o name)
      echo ---- End Spark Driver Log ----
      echo "Terminal SparkApplication $APP_NAME state is $(kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}')"
      # Test successful iff final state is COMPLETED. Use exit code from grep.
      kcfw get sparkapplication $APP_NAME -o jsonpath='{.status.applicationState.state}' | grep COMPLETED > /dev/null
    kubeconfig: |
      apiVersion: v1
      clusters:
      - cluster:
          certificate-authority: /certs/ca.pem
          server: https://kubernetes-api-test-flowsnake-prd.slb.sfdc.net
        name: kubernetes
      contexts:
      - context:
          cluster: kubernetes
          user: kubernetes
        name: default-context
      current-context: default-context
      kind: Config
      preferences: {}
      users:
      - name: kubernetes
        user:
          client-certificate: /certs/client/certificates/client.pem
          client-key: /certs/client/keys/client-key.pem
  kind: ConfigMap
  metadata:
    name: watchdog-spark-on-k8s-script-configmap
    namespace: flowsnake
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    labels:
      name: watchdog-spark-operator
    name: watchdog-spark-operator
    namespace: flowsnake
  spec:
    selector:
      matchLabels:
        app: watchdog-spark-operator
        apptype: monitoring
    template:
      metadata:
        annotations:
          madkub.sam.sfdc.net/allcerts: '{"certreqs": [{"cert-type": "client", "kingdom":
            "prd", "name": "watchdogsparkoperator", "role": "flowsnake_test.flowsnake-watchdog"}]}'
        labels:
          app: watchdog-spark-operator
          apptype: monitoring
          flowsnakeOwner: dva-transform
          flowsnakeRole: WatchdogSparkOperator
      spec:
        containers:
        - command:
          - /sam/watchdog
          - -role=CLI
          - -emailFrequency=72h
          - -timeout=2s
          - -funnelEndpoint=ajna0-funnel1-0-prd.data.sfdc.net:80
          - --config=/config/watchdog.json
          - -cliCheckerCommandTarget=SparkOperatorTest
          - --hostsConfigFile=/sfdchosts/hosts.json
          - -watchdogFrequency=1m
          - -alertThreshold=1m
          - -cliCheckerTimeout=15m
          image: ops0-artifactrepo2-0-prd.data.sfdc.net/docker-release-candidate/tnrp/sam/hypersam:sam-0002530-db32f9dc
          imagePullPolicy: IfNotPresent
          name: watchdog
          resources:
            limits:
              cpu: "1"
              memory: 500Mi
            requests:
              cpu: "1"
              memory: 500Mi
          volumeMounts:
          - mountPath: /config
            name: config
          - mountPath: /sfdchosts
            name: sfdchosts
          - mountPath: /watchdog-spark-scripts
            name: watchdog-spark-scripts
          - mountPath: /watchdog-spark-specs
            name: watchdog-spark-specs
          - mountPath: /certs
            name: datacerts
        - args:
          - /sam/madkub-client
          - --madkub-endpoint
          - https://10.254.208.254:32007
          - --maddog-endpoint
          - https://all.pkicontroller.pki.blank.prd.prod.non-estates.sfdcsd.net:8443
          - --maddog-server-ca
          - /etc/pki_service/ca/security-ca.pem
          - --madkub-server-ca
          - /etc/pki_service/ca/cacerts.pem
          - --token-folder
          - /tokens
          - --kingdom
          - prd
          - --superpod
          - None
          - --estate
          - prd-data-flowsnake_test
          - --refresher
          - --run-init-for-refresher-mode
          - --cert-folders
          - watchdogsparkoperator:/certs
          - --ca-folder
          - /etc/pki_service/ca
          - --funnel-endpoint
          - http://ajna0-funnel1-0-prd.data.sfdc.net:80
          env:
          - name: MADKUB_NODENAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: MADKUB_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MADKUB_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: ops0-artifactrepo2-0-prd.data.sfdc.net/docker-release-candidate/tnrp/sam/madkub:1.0.0-0000084-9f4a6ca6
          name: sam-madkub-integration-refresher
          resources: {}
          volumeMounts:
          - mountPath: /certs
            name: datacerts
          - mountPath: /tokens
            name: tokens
          - mountPath: /etc/pki_service/ca
            name: certificate-authority
            readOnly: true
          - mountPath: /etc/pki_service/platform/platform-client/certificates
            name: client-certificate
            readOnly: true
          - mountPath: /etc/pki_service/platform/platform-client/keys
            name: client-key
            readOnly: true
        hostNetwork: true
        initContainers:
        - args:
          - /sam/madkub-client
          - --madkub-endpoint
          - https://10.254.208.254:32007
          - --maddog-endpoint
          - https://all.pkicontroller.pki.blank.prd.prod.non-estates.sfdcsd.net:8443
          - --maddog-server-ca
          - /etc/pki_service/ca/security-ca.pem
          - --madkub-server-ca
          - /etc/pki_service/ca/cacerts.pem
          - --token-folder
          - /tokens
          - --kingdom
          - prd
          - --superpod
          - None
          - --estate
          - prd-data-flowsnake_test
          - --cert-folders
          - watchdogsparkoperator:/certs
          - --ca-folder
          - /etc/pki_service/ca
          - --funnel-endpoint
          - http://ajna0-funnel1-0-prd.data.sfdc.net:80
          env:
          - name: MADKUB_NODENAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: MADKUB_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: MADKUB_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: ops0-artifactrepo2-0-prd.data.sfdc.net/docker-release-candidate/tnrp/sam/madkub:1.0.0-0000084-9f4a6ca6
          name: sam-madkub-integration-init
          resources: {}
          volumeMounts:
          - mountPath: /certs
            name: datacerts
          - mountPath: /tokens
            name: tokens
          - mountPath: /etc/pki_service/ca
            name: certificate-authority
            readOnly: true
          - mountPath: /etc/pki_service/platform/platform-client/certificates
            name: client-certificate
            readOnly: true
          - mountPath: /etc/pki_service/platform/platform-client/keys
            name: client-key
            readOnly: true
        restartPolicy: Always
        serviceAccount: watchdog-spark-operator-serviceaccount
        serviceAccountName: watchdog-spark-operator-serviceaccount
        volumes:
        - configMap:
            name: watchdog
          name: config
        - configMap:
            name: watchdog-spark-on-k8s-spec-configmap
          name: watchdog-spark-specs
        - configMap:
            defaultMode: 493
            name: watchdog-spark-on-k8s-script-configmap
          name: watchdog-spark-scripts
        - configMap:
            name: sfdchosts
          name: sfdchosts
kind: List
metadata: {}
